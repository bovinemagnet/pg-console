= Database Schema
Paul Snow
0.0.0
:description: Database schema design for pg-console historical data and alert storage
:keywords: database, schema, Flyway, migrations, history

include::_attributes.adoc[]

This page describes the database schema used by pg-console for storing historical metrics and how Flyway manages schema migrations.

== Overview

By default, pg-console creates a dedicated schema named `pgconsole` in the monitored PostgreSQL database. This schema stores:

* System-level metrics history (connections, cache hits, blocking queries, database size)
* Query performance metrics from `pg_stat_statements`
* Per-database metrics history (transactions, cache hits, deadlocks, tuple operations)
* Audit logs, bookmarks, notifications, and insights (extended features)

The schema is created and managed automatically using Flyway migrations, which run on application startup.

IMPORTANT: pg-console requires `CREATE SCHEMA` and `CREATE TABLE` privileges to initialise its schema. See xref:admin-guide:deployment.adoc#database-permissions[Database Permissions] for details.

=== Metadata Datasource Separation

The `pgconsole` schema can be stored in a separate database from the one being monitored. This enables:

* Read-only monitoring of production databases
* Centralised metadata storage for multi-instance deployments
* Cleaner separation between monitored and monitoring data

Configure using `PG_CONSOLE_METADATA_DATASOURCE` to specify a dedicated datasource or use an existing instance's datasource. See xref:admin-guide:configuration.adoc#_metadata_datasource_separation[Metadata Datasource Separation] for configuration details.

=== Schema-Free Mode

pg-console can also operate without creating any database schema. When `PG_CONSOLE_SCHEMA_ENABLED=false`, all schema creation is disabled:

* No `pgconsole` schema is created
* Flyway migrations are completely skipped
* Real-time monitoring continues to work normally
* Short-term trends use in-memory storage instead of database persistence

This is particularly useful for read-only monitoring scenarios. See xref:admin-guide:schema-free-mode.adoc[Schema-Free Mode] for complete details.

== Schema Design

The `pgconsole` schema is designed for time-series data storage with efficient querying and automatic retention management.

=== Design Principles

Denormalised storage::
Historical data is stored in a denormalised format optimised for time-series queries rather than relational normalisation.

Time-based partitioning (future)::
Schema is designed to support table partitioning by timestamp for improved query performance on large datasets.

Automatic cleanup::
Retention policies are enforced by a scheduled job that purges records older than the configured retention period.

Minimal indexes::
Only essential indexes are created to balance query performance with write overhead.

== Entity Relationship Diagram

The following diagram shows the relationships between tables in the `pgconsole` schema:

include::example$erd-schema.mmd[]

== Core History Tables

These tables store time-series metrics sampled periodically for trend visualisation and historical analysis.

=== system_metrics_history

Stores periodic snapshots of system-level database health metrics across all monitored databases.

[cols="1,1,3"]
|===
|Column |Type |Description

|`id`
|`BIGSERIAL`
|Primary key (auto-incrementing)

|`sampled_at`
|`TIMESTAMP WITH TIME ZONE`
|When the sample was taken

|`instance_id`
|`TEXT`
|PostgreSQL instance identifier (default: 'default')

|`total_connections`
|`INTEGER`
|Total number of database connections

|`max_connections`
|`INTEGER`
|Maximum allowed connections

|`active_queries`
|`INTEGER`
|Number of queries currently executing

|`idle_connections`
|`INTEGER`
|Number of connections in idle state

|`idle_in_transaction`
|`INTEGER`
|Number of connections idle in transaction

|`blocked_queries`
|`INTEGER`
|Number of queries blocked by locks

|`longest_query_seconds`
|`DOUBLE PRECISION`
|Duration of longest running query in seconds

|`longest_transaction_seconds`
|`DOUBLE PRECISION`
|Duration of longest running transaction in seconds

|`cache_hit_ratio`
|`DOUBLE PRECISION`
|Buffer cache hit ratio (aggregated across databases)

|`total_database_size_bytes`
|`BIGINT`
|Total size of all monitored databases in bytes
|===

==== Indexes

`idx_system_metrics_instance_sampled`::
B-tree index on `(instance_id, sampled_at DESC)` for efficient time-range queries per instance.

==== Sample Query

[source,sql]
----
SELECT sampled_at, total_connections, cache_hit_ratio, blocked_queries
FROM pgconsole.system_metrics_history
WHERE instance_id = 'default'
  AND sampled_at >= NOW() - INTERVAL '1 hour'
ORDER BY sampled_at;
----

=== query_metrics_history

Stores periodic snapshots of query performance metrics from `pg_stat_statements`.

[cols="1,1,3"]
|===
|Column |Type |Description

|`id`
|`BIGSERIAL`
|Primary key (auto-incrementing)

|`sampled_at`
|`TIMESTAMP WITH TIME ZONE`
|When the sample was taken

|`instance_id`
|`TEXT`
|PostgreSQL instance identifier (default: 'default')

|`query_id`
|`TEXT`
|Hash identifier from `pg_stat_statements`

|`query_text`
|`TEXT`
|Normalised SQL query text

|`total_calls`
|`BIGINT`
|Number of times executed (cumulative counter)

|`total_time_ms`
|`DOUBLE PRECISION`
|Total execution time in milliseconds (cumulative counter)

|`total_rows`
|`BIGINT`
|Total number of rows returned (cumulative counter)

|`mean_time_ms`
|`DOUBLE PRECISION`
|Average execution time in milliseconds

|`min_time_ms`
|`DOUBLE PRECISION`
|Minimum execution time in milliseconds

|`max_time_ms`
|`DOUBLE PRECISION`
|Maximum execution time in milliseconds

|`stddev_time_ms`
|`DOUBLE PRECISION`
|Standard deviation of execution time

|`shared_blks_hit`
|`BIGINT`
|Shared blocks read from cache

|`shared_blks_read`
|`BIGINT`
|Shared blocks read from disk

|`temp_blks_written`
|`BIGINT`
|Temporary blocks written to disk
|===

==== Indexes

`idx_query_metrics_instance_sampled`::
B-tree index on `(instance_id, sampled_at DESC)` for time-range queries per instance.

`idx_query_metrics_instance_query`::
B-tree index on `(instance_id, query_id, sampled_at DESC)` for tracking specific queries over time.

==== Sample Query

[source,sql]
----
SELECT sampled_at, total_calls, mean_time_ms
FROM pgconsole.query_metrics_history
WHERE instance_id = 'default'
  AND query_id = '1234567890'
  AND sampled_at >= NOW() - INTERVAL '24 hours'
ORDER BY sampled_at;
----

=== database_metrics_history

Stores periodic snapshots of per-database statistics including connection counts, transaction rates, cache hit ratios, tuple operations, and problem indicators like deadlocks.

[cols="1,1,3"]
|===
|Column |Type |Description

|`id`
|`BIGSERIAL`
|Primary key (auto-incrementing)

|`sampled_at`
|`TIMESTAMP WITH TIME ZONE`
|When the sample was taken

|`instance_id`
|`TEXT`
|PostgreSQL instance identifier (default: 'default')

|`database_name`
|`TEXT`
|Name of the database being monitored

|`num_backends`
|`INTEGER`
|Number of backends currently connected to this database

|`xact_commit`
|`BIGINT`
|Number of transactions committed (cumulative counter)

|`xact_rollback`
|`BIGINT`
|Number of transactions rolled back (cumulative counter)

|`blks_hit`
|`BIGINT`
|Shared blocks read from cache (cumulative counter)

|`blks_read`
|`BIGINT`
|Shared blocks read from disk (cumulative counter)

|`cache_hit_ratio`
|`DOUBLE PRECISION`
|Buffer cache hit ratio for this database

|`tup_returned`
|`BIGINT`
|Tuples returned by queries (cumulative counter)

|`tup_fetched`
|`BIGINT`
|Tuples fetched by queries (cumulative counter)

|`tup_inserted`
|`BIGINT`
|Tuples inserted (cumulative counter)

|`tup_updated`
|`BIGINT`
|Tuples updated (cumulative counter)

|`tup_deleted`
|`BIGINT`
|Tuples deleted (cumulative counter)

|`deadlocks`
|`BIGINT`
|Number of deadlocks detected (cumulative counter)

|`conflicts`
|`BIGINT`
|Number of queries cancelled due to conflicts (cumulative counter)

|`temp_files`
|`BIGINT`
|Number of temporary files created (cumulative counter)

|`temp_bytes`
|`BIGINT`
|Total bytes written to temporary files (cumulative counter)

|`database_size_bytes`
|`BIGINT`
|Total size of the database in bytes
|===

==== Indexes

`idx_database_metrics_instance_sampled`::
B-tree index on `(instance_id, sampled_at DESC)` for time-range queries per instance.

`idx_database_metrics_instance_db`::
B-tree index on `(instance_id, database_name, sampled_at DESC)` for tracking specific databases over time.

==== Sample Query

[source,sql]
----
SELECT sampled_at, database_name, num_backends, cache_hit_ratio, deadlocks
FROM pgconsole.database_metrics_history
WHERE instance_id = 'default'
  AND database_name = 'myapp_prod'
  AND sampled_at >= NOW() - INTERVAL '24 hours'
ORDER BY sampled_at;
----

== Flyway Migrations

pg-console uses Flyway to manage database schema migrations. Migration scripts are located in `src/main/resources/db/migration/` and follow Flyway's naming convention.

NOTE: When operating in xref:admin-guide:schema-free-mode.adoc[Schema-Free Mode] (`PG_CONSOLE_SCHEMA_ENABLED=false`), Flyway is completely disabled and no migrations run.

=== Migration Files

`V1__initial_schema.sql`::
Creates the complete `pgconsole` schema including all tables, indexes, and constraints. This comprehensive migration creates:
+
* Core history tables (`system_metrics_history`, `query_metrics_history`, `database_metrics_history`)
* Audit and bookkeeping tables (`audit_log`, `query_bookmark`, `scheduled_report`)
* Schema comparison tables (`comparison_profile`, `comparison_history`)
* Notification infrastructure (`notification_channel`, `escalation_policy`, `alert_acknowledgement`, `active_alert`, etc.)
* Insights and intelligence tables (`metric_baseline`, `detected_anomaly`, `metric_forecast`, `unified_recommendation`)
* Natural language query support (`nl_query_pattern`, `nl_query_history`)
* Runbook automation (`runbook`, `runbook_execution`)
* Scheduled maintenance tracking (`scheduled_maintenance`, `maintenance_execution`)
* Custom dashboards (`custom_dashboard`, `custom_widget`)

All schema objects are created in a single migration to ensure consistency and simplify initial deployment.

=== Migration Execution

Flyway automatically runs migrations on application startup:

. Checks for the `flyway_schema_history` table
. Creates it if it doesn't exist
. Compares checksum of each migration file
. Runs any new migrations in version order
. Records successful migrations in `flyway_schema_history`

=== Migration Best Practices

When creating new migrations:

* Use sequential version numbers: `V5__`, `V6__`, etc.
* Write descriptive migration names: `V5__add_index_to_query_history.sql`
* Make migrations idempotent where possible (e.g., `CREATE TABLE IF NOT EXISTS`)
* Test migrations on a copy of production data
* Never modify existing migration files after they've been applied
* Use separate migrations for schema changes and data migrations

=== Example Migration

Here's an example migration file structure:

[source,sql]
----
-- V5__add_database_name_to_query_history.sql

-- Add database name column to track queries per database
ALTER TABLE pgconsole.query_history
ADD COLUMN database_name VARCHAR(255);

-- Create index for filtering by database
CREATE INDEX idx_query_history_database_name
ON pgconsole.query_history(database_name);

-- Backfill existing records with default database
UPDATE pgconsole.query_history
SET database_name = 'postgres'
WHERE database_name IS NULL;

-- Make column non-nullable
ALTER TABLE pgconsole.query_history
ALTER COLUMN database_name SET NOT NULL;
----

== Data Retention and Cleanup

pg-console implements automatic data retention to prevent unbounded growth of historical tables.

=== Retention Policy

The retention period is configured via the `PG_CONSOLE_HISTORY_RETENTION` environment variable:

* Default: `7` days
* Configurable: Any positive integer representing days
* Applies to: All tables in the `pgconsole` schema

=== Cleanup Process

The `MetricsSamplerService` runs a daily cleanup job that:

. Calculates the cutoff timestamp: `NOW() - INTERVAL '\{retention} days'`
. Deletes records older than the cutoff from each history table:
  * `system_metrics_history`
  * `query_metrics_history`
  * `database_metrics_history`
. Logs the number of records deleted
. Runs `VACUUM` to reclaim storage space

=== Cleanup SQL

[source,sql]
----
-- Delete old system metrics history
DELETE FROM pgconsole.system_metrics_history
WHERE sampled_at < NOW() - INTERVAL '7 days';

-- Delete old query metrics history
DELETE FROM pgconsole.query_metrics_history
WHERE sampled_at < NOW() - INTERVAL '7 days';

-- Delete old database metrics history
DELETE FROM pgconsole.database_metrics_history
WHERE sampled_at < NOW() - INTERVAL '7 days';

-- Reclaim storage
VACUUM pgconsole.system_metrics_history;
VACUUM pgconsole.query_metrics_history;
VACUUM pgconsole.database_metrics_history;
----

=== Disabling Retention

To retain all historical data indefinitely:

[source,bash]
----
export PG_CONSOLE_HISTORY_RETENTION=0
----

Setting retention to `0` disables automatic cleanup. Manual cleanup via SQL will be required.

WARNING: Disabling retention can lead to unbounded table growth. Monitor disk usage and implement manual archival if needed.

== Schema Permissions

pg-console requires specific PostgreSQL permissions to create and manage its schema.

=== Initial Setup Permissions

Required for first-time schema creation:

[source,sql]
----
-- Create a dedicated user for pg-console
CREATE USER pgconsole_app WITH PASSWORD 'secure_password';

-- Grant schema creation privilege
GRANT CREATE ON DATABASE postgres TO pgconsole_app;

-- Grant access to system views
GRANT pg_read_all_stats TO pgconsole_app;
----

=== Runtime Permissions

Required for normal operation after schema exists:

[source,sql]
----
-- Grant usage on the schema
GRANT USAGE ON SCHEMA pgconsole TO pgconsole_app;

-- Grant table permissions
GRANT SELECT, INSERT, DELETE ON ALL TABLES IN SCHEMA pgconsole TO pgconsole_app;

-- Grant sequence permissions for auto-increment columns
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA pgconsole TO pgconsole_app;

-- Grant default privileges for future tables
ALTER DEFAULT PRIVILEGES IN SCHEMA pgconsole
GRANT SELECT, INSERT, DELETE ON TABLES TO pgconsole_app;
----

== Querying Historical Data

pg-console provides several endpoints for querying historical data via the web interface. Developers can also query the schema directly for custom analysis.

=== Sparkline Data

Sparklines on the dashboard use time-windowed queries:

[source,sql]
----
SELECT sampled_at, total_connections
FROM pgconsole.system_metrics_history
WHERE instance_id = 'default'
  AND sampled_at >= NOW() - INTERVAL '1 hour'
ORDER BY sampled_at;
----

=== Trend Analysis

Identify trends by comparing recent averages to historical baselines:

[source,sql]
----
WITH recent AS (
  SELECT AVG(cache_hit_ratio) AS avg_ratio
  FROM pgconsole.system_metrics_history
  WHERE instance_id = 'default'
    AND sampled_at >= NOW() - INTERVAL '1 hour'
),
baseline AS (
  SELECT AVG(cache_hit_ratio) AS avg_ratio
  FROM pgconsole.system_metrics_history
  WHERE instance_id = 'default'
    AND sampled_at BETWEEN NOW() - INTERVAL '7 days'
    AND NOW() - INTERVAL '1 hour'
)
SELECT
  recent.avg_ratio AS recent_cache_hit,
  baseline.avg_ratio AS baseline_cache_hit,
  recent.avg_ratio - baseline.avg_ratio AS difference
FROM recent, baseline;
----

=== Top Queries Over Time

Track query performance changes over time:

[source,sql]
----
SELECT
  query_text,
  sampled_at,
  total_calls,
  mean_time_ms,
  max_time_ms
FROM pgconsole.query_metrics_history
WHERE instance_id = 'default'
  AND query_id = '1234567890'
  AND sampled_at >= NOW() - INTERVAL '7 days'
ORDER BY sampled_at DESC;
----

=== Database-Specific Metrics

Analyse per-database metrics including deadlock trends:

[source,sql]
----
SELECT
  sampled_at,
  database_name,
  deadlocks,
  conflicts,
  cache_hit_ratio,
  num_backends
FROM pgconsole.database_metrics_history
WHERE instance_id = 'default'
  AND sampled_at >= NOW() - INTERVAL '24 hours'
ORDER BY database_name, sampled_at;
----

== Next Steps

Now that you understand the database schema, explore:

* xref:testing.adoc[Testing] - Learn about the test strategy and coverage
* xref:architecture.adoc[Architecture] - Review the overall system design
* xref:admin-guide:configuration.adoc[Configuration] - Configure retention and sampling intervals
