= Database Schema
Paul Snow
0.0.0
:description: Database schema design for pg-console historical data and alert storage
:keywords: database, schema, Flyway, migrations, history

This page describes the database schema used by pg-console for storing historical metrics, alert data, and how Flyway manages schema migrations.

== Overview

By default, pg-console creates a dedicated schema named `pgconsole` in the monitored PostgreSQL database. This schema stores:

* Historical overview statistics (connections, cache hits, database size)
* Historical query performance metrics from `pg_stat_statements`
* Alert history and notification records

The schema is created and managed automatically using Flyway migrations, which run on application startup.

IMPORTANT: pg-console requires `CREATE SCHEMA` and `CREATE TABLE` privileges to initialise its schema. See xref:admin-guide:deployment.adoc#database-permissions[Database Permissions] for details.

=== Schema-Free Mode

pg-console can also operate without creating any database schema. When `PG_CONSOLE_SCHEMA_ENABLED=false`, all schema creation is disabled:

* No `pgconsole` schema is created
* Flyway migrations are completely skipped
* Real-time monitoring continues to work normally
* Short-term trends use in-memory storage instead of database persistence

This is particularly useful for read-only monitoring scenarios. See xref:admin-guide:schema-free-mode.adoc[Schema-Free Mode] for complete details.

== Schema Design

The `pgconsole` schema is designed for time-series data storage with efficient querying and automatic retention management.

=== Design Principles

Denormalised storage::
Historical data is stored in a denormalised format optimised for time-series queries rather than relational normalisation.

Time-based partitioning (future)::
Schema is designed to support table partitioning by timestamp for improved query performance on large datasets.

Automatic cleanup::
Retention policies are enforced by a scheduled job that purges records older than the configured retention period.

Minimal indexes::
Only essential indexes are created to balance query performance with write overhead.

== Entity Relationship Diagram

The following diagram shows the relationships between tables in the `pgconsole` schema:

include::example$erd-schema.mmd[]

== Tables

=== overview_history

Stores periodic snapshots of overall database health metrics.

[cols="1,1,3"]
|===
|Column |Type |Description

|`id`
|`BIGSERIAL`
|Primary key (auto-incrementing)

|`sample_time`
|`TIMESTAMP`
|When the sample was taken

|`total_connections`
|`INTEGER`
|Total number of database connections

|`active_connections`
|`INTEGER`
|Number of connections in active state

|`idle_connections`
|`INTEGER`
|Number of connections in idle state

|`blocked_queries`
|`INTEGER`
|Number of queries blocked by locks

|`cache_hit_ratio`
|`NUMERIC(5,2)`
|Buffer cache hit ratio as percentage (0-100)

|`database_size_bytes`
|`BIGINT`
|Total size of all databases in bytes

|`transactions_per_sec`
|`NUMERIC(10,2)`
|Transactions committed per second

|`tuples_inserted`
|`BIGINT`
|Cumulative tuples inserted

|`tuples_updated`
|`BIGINT`
|Cumulative tuples updated

|`tuples_deleted`
|`BIGINT`
|Cumulative tuples deleted
|===

==== Indexes

`idx_overview_history_sample_time`::
B-tree index on `sample_time` for efficient time-range queries.

==== Sample Query

[source,sql]
----
SELECT sample_time, total_connections, cache_hit_ratio
FROM pgconsole.overview_history
WHERE sample_time >= NOW() - INTERVAL '1 hour'
ORDER BY sample_time;
----

=== query_history

Stores periodic snapshots of query performance metrics from `pg_stat_statements`.

[cols="1,1,3"]
|===
|Column |Type |Description

|`id`
|`BIGSERIAL`
|Primary key (auto-incrementing)

|`sample_time`
|`TIMESTAMP`
|When the sample was taken

|`query_id`
|`BIGINT`
|Hash identifier from `pg_stat_statements`

|`query_text`
|`TEXT`
|Normalised SQL query text

|`calls`
|`BIGINT`
|Number of times executed

|`total_time`
|`NUMERIC(20,3)`
|Total execution time in milliseconds

|`min_time`
|`NUMERIC(20,3)`
|Minimum execution time in milliseconds

|`max_time`
|`NUMERIC(20,3)`
|Maximum execution time in milliseconds

|`mean_time`
|`NUMERIC(20,3)`
|Average execution time in milliseconds

|`stddev_time`
|`NUMERIC(20,3)`
|Standard deviation of execution time

|`rows`
|`BIGINT`
|Total number of rows returned

|`shared_blks_hit`
|`BIGINT`
|Shared blocks read from cache

|`shared_blks_read`
|`BIGINT`
|Shared blocks read from disk

|`temp_blks_written`
|`BIGINT`
|Temporary blocks written to disk
|===

==== Indexes

`idx_query_history_sample_time`::
B-tree index on `sample_time` for time-range queries.

`idx_query_history_query_id`::
B-tree index on `query_id` for tracking specific queries over time.

==== Sample Query

[source,sql]
----
SELECT sample_time, calls, mean_time
FROM pgconsole.query_history
WHERE query_id = 1234567890
  AND sample_time >= NOW() - INTERVAL '24 hours'
ORDER BY sample_time;
----

=== alert_history

Stores historical alerts and notifications generated by pg-console monitoring rules.

[cols="1,1,3"]
|===
|Column |Type |Description

|`id`
|`BIGSERIAL`
|Primary key (auto-incrementing)

|`alert_time`
|`TIMESTAMP`
|When the alert was triggered

|`alert_type`
|`VARCHAR(50)`
|Type of alert (e.g., `HIGH_CONNECTIONS`, `LONG_RUNNING_QUERY`)

|`severity`
|`VARCHAR(20)`
|Severity level (`INFO`, `WARNING`, `CRITICAL`)

|`message`
|`TEXT`
|Human-readable alert message

|`details`
|`JSONB`
|Additional alert context as JSON

|`resolved`
|`BOOLEAN`
|Whether the alert has been resolved

|`resolved_time`
|`TIMESTAMP`
|When the alert was resolved (if applicable)
|===

==== Indexes

`idx_alert_history_alert_time`::
B-tree index on `alert_time` for time-range queries.

`idx_alert_history_alert_type`::
B-tree index on `alert_type` for filtering by alert type.

`idx_alert_history_severity`::
B-tree index on `severity` for filtering by severity level.

==== Sample Query

[source,sql]
----
SELECT alert_time, alert_type, severity, message
FROM pgconsole.alert_history
WHERE severity = 'CRITICAL'
  AND resolved = false
ORDER BY alert_time DESC
LIMIT 10;
----

== Flyway Migrations

pg-console uses Flyway to manage database schema migrations. Migration scripts are located in `src/main/resources/db/migration/` and follow Flyway's naming convention.

NOTE: When operating in xref:admin-guide:schema-free-mode.adoc[Schema-Free Mode] (`PG_CONSOLE_SCHEMA_ENABLED=false`), Flyway is completely disabled and no migrations run.

=== Migration Files

`V1__create_pgconsole_schema.sql`::
Creates the `pgconsole` schema and sets the search path.

`V2__create_overview_history_table.sql`::
Creates the `overview_history` table with indexes.

`V3__create_query_history_table.sql`::
Creates the `query_history` table with indexes.

`V4__create_alert_history_table.sql`::
Creates the `alert_history` table with indexes.

=== Migration Execution

Flyway automatically runs migrations on application startup:

. Checks for the `flyway_schema_history` table
. Creates it if it doesn't exist
. Compares checksum of each migration file
. Runs any new migrations in version order
. Records successful migrations in `flyway_schema_history`

=== Migration Best Practices

When creating new migrations:

* Use sequential version numbers: `V5__`, `V6__`, etc.
* Write descriptive migration names: `V5__add_index_to_query_history.sql`
* Make migrations idempotent where possible (e.g., `CREATE TABLE IF NOT EXISTS`)
* Test migrations on a copy of production data
* Never modify existing migration files after they've been applied
* Use separate migrations for schema changes and data migrations

=== Example Migration

Here's an example migration file structure:

[source,sql]
----
-- V5__add_database_name_to_query_history.sql

-- Add database name column to track queries per database
ALTER TABLE pgconsole.query_history
ADD COLUMN database_name VARCHAR(255);

-- Create index for filtering by database
CREATE INDEX idx_query_history_database_name
ON pgconsole.query_history(database_name);

-- Backfill existing records with default database
UPDATE pgconsole.query_history
SET database_name = 'postgres'
WHERE database_name IS NULL;

-- Make column non-nullable
ALTER TABLE pgconsole.query_history
ALTER COLUMN database_name SET NOT NULL;
----

== Data Retention and Cleanup

pg-console implements automatic data retention to prevent unbounded growth of historical tables.

=== Retention Policy

The retention period is configured via the `PG_CONSOLE_HISTORY_RETENTION` environment variable:

* Default: `7` days
* Configurable: Any positive integer representing days
* Applies to: All tables in the `pgconsole` schema

=== Cleanup Process

The `MetricsSamplerService` runs a daily cleanup job that:

. Calculates the cutoff timestamp: `NOW() - INTERVAL '{retention} days'`
. Deletes records older than the cutoff from each table:
  * `overview_history`
  * `query_history`
  * `alert_history`
. Logs the number of records deleted
. Runs `VACUUM` to reclaim storage space

=== Cleanup SQL

[source,sql]
----
-- Delete old overview history
DELETE FROM pgconsole.overview_history
WHERE sample_time < NOW() - INTERVAL '7 days';

-- Delete old query history
DELETE FROM pgconsole.query_history
WHERE sample_time < NOW() - INTERVAL '7 days';

-- Delete old resolved alerts
DELETE FROM pgconsole.alert_history
WHERE alert_time < NOW() - INTERVAL '7 days'
  AND resolved = true;

-- Reclaim storage
VACUUM pgconsole.overview_history;
VACUUM pgconsole.query_history;
VACUUM pgconsole.alert_history;
----

NOTE: Unresolved alerts are retained beyond the retention period to ensure ongoing issues remain visible.

=== Disabling Retention

To retain all historical data indefinitely:

[source,bash]
----
export PG_CONSOLE_HISTORY_RETENTION=0
----

Setting retention to `0` disables automatic cleanup. Manual cleanup via SQL will be required.

WARNING: Disabling retention can lead to unbounded table growth. Monitor disk usage and implement manual archival if needed.

== Schema Permissions

pg-console requires specific PostgreSQL permissions to create and manage its schema.

=== Initial Setup Permissions

Required for first-time schema creation:

[source,sql]
----
-- Create a dedicated user for pg-console
CREATE USER pgconsole_app WITH PASSWORD 'secure_password';

-- Grant schema creation privilege
GRANT CREATE ON DATABASE postgres TO pgconsole_app;

-- Grant access to system views
GRANT pg_read_all_stats TO pgconsole_app;
----

=== Runtime Permissions

Required for normal operation after schema exists:

[source,sql]
----
-- Grant usage on the schema
GRANT USAGE ON SCHEMA pgconsole TO pgconsole_app;

-- Grant table permissions
GRANT SELECT, INSERT, DELETE ON ALL TABLES IN SCHEMA pgconsole TO pgconsole_app;

-- Grant sequence permissions for auto-increment columns
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA pgconsole TO pgconsole_app;

-- Grant default privileges for future tables
ALTER DEFAULT PRIVILEGES IN SCHEMA pgconsole
GRANT SELECT, INSERT, DELETE ON TABLES TO pgconsole_app;
----

== Querying Historical Data

pg-console provides several endpoints for querying historical data via the web interface. Developers can also query the schema directly for custom analysis.

=== Sparkline Data

Sparklines on the dashboard use time-windowed queries:

[source,sql]
----
SELECT sample_time, total_connections
FROM pgconsole.overview_history
WHERE sample_time >= NOW() - INTERVAL '1 hour'
ORDER BY sample_time;
----

=== Trend Analysis

Identify trends by comparing recent averages to historical baselines:

[source,sql]
----
WITH recent AS (
  SELECT AVG(cache_hit_ratio) AS avg_ratio
  FROM pgconsole.overview_history
  WHERE sample_time >= NOW() - INTERVAL '1 hour'
),
baseline AS (
  SELECT AVG(cache_hit_ratio) AS avg_ratio
  FROM pgconsole.overview_history
  WHERE sample_time BETWEEN NOW() - INTERVAL '7 days'
    AND NOW() - INTERVAL '1 hour'
)
SELECT
  recent.avg_ratio AS recent_cache_hit,
  baseline.avg_ratio AS baseline_cache_hit,
  recent.avg_ratio - baseline.avg_ratio AS difference
FROM recent, baseline;
----

=== Top Queries Over Time

Track query performance changes over time:

[source,sql]
----
SELECT
  query_text,
  sample_time,
  calls,
  mean_time,
  max_time
FROM pgconsole.query_history
WHERE query_id = 1234567890
  AND sample_time >= NOW() - INTERVAL '7 days'
ORDER BY sample_time DESC;
----

== Next Steps

Now that you understand the database schema, explore:

* xref:testing.adoc[Testing] - Learn about the test strategy and coverage
* xref:architecture.adoc[Architecture] - Review the overall system design
* xref:admin-guide:configuration.adoc[Configuration] - Configure retention and sampling intervals
